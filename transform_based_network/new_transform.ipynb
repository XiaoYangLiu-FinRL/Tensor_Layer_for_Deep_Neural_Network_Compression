{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_dct as dct\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pkbar\n",
    "import math\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from common import *\n",
    "from transform_based_network import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define super parameters\n",
    "lr_rate = 0.01\n",
    "epochs_num = 20\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 100\n",
    "train_loader, test_loader = load_mnist_multiprocess(batch_size)\n",
    "\n",
    "\n",
    "# define nn module\n",
    "class tNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(tNN, self).__init__()\n",
    "        W, B = [], []\n",
    "        self.num_layers = 4\n",
    "        for i in range(self.num_layers):\n",
    "            W.append(nn.Parameter(torch.Tensor(28, 28, 28)))\n",
    "            B.append(nn.Parameter(torch.Tensor(28, 28, 1)))\n",
    "        self.W = nn.ParameterList(W)\n",
    "        self.B = nn.ParameterList(B)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.num_layers):\n",
    "            x = torch.add(t_product(self.W[i], x), self.B[i])\n",
    "            x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for i in range(self.num_layers):\n",
    "            init.kaiming_uniform_(self.W[i], a=math.sqrt(5))\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.W[i])\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            init.uniform_(self.B[i], -bound, bound)\n",
    "\n",
    "\n",
    "module = tNN()\n",
    "module = module.to(device)\n",
    "\n",
    "Loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(module.parameters(), lr=lr_rate)\n",
    "\n",
    "test_loss_epoch = []\n",
    "test_acc_epoch = []\n",
    "train_loss_epoch = []\n",
    "train_acc_epoch = []\n",
    "time_list = []\n",
    "\n",
    "# begain train\n",
    "for epoch in range(epochs_num):\n",
    "    since = time.time()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    module.train()\n",
    "\n",
    "    pbar_train = pkbar.Pbar(name='Epoch '+str(epoch+1)+' training:', target=60000/batch_size)\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        img, label = data\n",
    "        img = raw_img(img, batch_size, n=28)\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        # forward\n",
    "        out = module(img)\n",
    "\n",
    "        # softmax function\n",
    "        out = torch.transpose(scalar_tubal_func(out), 0, 1)\n",
    "        loss = Loss_function(out, label)\n",
    "        running_loss += loss.item()\n",
    "        _, pred = torch.max(out, 1)\n",
    "        running_acc += (pred == label).float().mean()\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pbar_train.update(i)\n",
    "\n",
    "    print('[{Epoch}/{Epochs_num}] Loss:{Running_loss} Acc:{Running_acc}'\n",
    "          .format(Epoch=epoch + 1, Epochs_num=epochs_num, Running_loss=(running_loss / i),\n",
    "                  Running_acc=running_acc / i))\n",
    "    train_loss_epoch.append(running_loss / i)\n",
    "    train_acc_epoch.append((running_acc / i) * 100)\n",
    "\n",
    "    module.eval()\n",
    "    eval_loss = 0.0\n",
    "    eval_acc = 0.0\n",
    "\n",
    "    pbar_test = pkbar.Pbar(name='Epoch '+str(epoch+1)+' test', target=10000/batch_size)\n",
    "    for i,data in enumerate(test_loader):\n",
    "        img, label = data\n",
    "        img = cifar_img_process(img)\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = module(img)\n",
    "            out = torch.transpose(scalar_tubal_func(out), 0, 1)\n",
    "            loss = Loss_function(out, label)\n",
    "        eval_loss += loss.item()\n",
    "        _, pred = torch.max(out, 1)\n",
    "        eval_acc += (pred == label).float().mean()\n",
    "\n",
    "        pbar_test.update(i)\n",
    "\n",
    "    print('Test Loss: {Eval_loss}, Acc: {Eval_acc}'\n",
    "          .format(Eval_loss=eval_loss / len(test_loader), Eval_acc=eval_acc / len(test_loader)))\n",
    "    test_loss_epoch.append(eval_loss / len(test_loader))\n",
    "    test_acc_epoch.append((eval_acc / len(test_loader)) * 100)\n",
    "    time_list.append(time.time() - since)\n",
    "\n",
    "    if np.isnan(eval_loss):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
