{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_dct as dct\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Pool, Queue, Process, set_start_method\n",
    "import multiprocessing as mp_\n",
    "\n",
    "import time\n",
    "import pkbar\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from common import *\n",
    "from transform_based_network import *\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T_Layer(nn.Module):\n",
    "    def __init__(self, dct_w, dct_b):\n",
    "        super(T_Layer, self).__init__()\n",
    "        self.weights = nn.Parameter(dct_w)\n",
    "        self.bias = nn.Parameter(dct_b)\n",
    "        \n",
    "    def forward(self, dct_x):\n",
    "        x = torch.mm(self.weights, dct_x) + self.bias\n",
    "        return x\n",
    "\n",
    "    \n",
    "class Frontal_Slice(nn.Module):\n",
    "    def __init__(self, dct_w, dct_b):\n",
    "        super(Frontal_Slice, self).__init__()\n",
    "        self.device = dct_w.device\n",
    "        self.dct_linear = nn.Sequential(\n",
    "            T_Layer(dct_w, dct_b),\n",
    "        )\n",
    "        #nn.ReLU(inplace=True),\n",
    "        #self.linear1 = nn.Linear(28, 28)\n",
    "        #nn.ReLU(inplace=True),\n",
    "        #self.classifier = nn.Linear(28, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = torch.transpose(x, 0, 1).to(self.device)\n",
    "        x = self.dct_linear(x)\n",
    "        #x = self.linear1(x)\n",
    "        #x = self.classifier(x)\n",
    "        #x = torch.transpose(x, 0, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_slice(i, model, x_i, y, outputs, optimizer):\n",
    "    s = time.time()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    o = torch.stack(outputs)\n",
    "    o[i, ...] = outputs_grad[i]\n",
    "    o = torch_apply(dct.idct, o)\n",
    "    o = scalar_tubal_func(o)\n",
    "    o = torch.transpose(o, 0, 1)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(o, y) \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    e = time.time()\n",
    "    # print(e - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "batch_size = 100\n",
    "trainloader, testloader = load_mnist_multiprocess(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (28, 28, batch_size)\n",
    "models = []\n",
    "ops = []\n",
    "dct_w, dct_b = make_weights(shape, device=device)\n",
    "for i in range(shape[0]):\n",
    "    w_i = dct_w[i, ...].clone()\n",
    "    b_i = dct_b[i, ...].clone()\n",
    "    \n",
    "    w_i.requires_grad = True\n",
    "    b_i.requires_grad = True\n",
    "    \n",
    "    model = Frontal_Slice(w_i, b_i)\n",
    "    model.train()\n",
    "    models.append(model.to(device))\n",
    "    \n",
    "    op = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "    ops.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "acc_list = []\n",
    "loss_list = []\n",
    "\n",
    "global outputs_grad\n",
    "for e in range(epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    losses = 0\n",
    "    pbar = pkbar.Pbar(name='Epoch '+str(e), target=60000/batch_size)\n",
    "    for batch_idx, (x, y) in enumerate(trainloader):   \n",
    "        dct_x = torch_shift(x)\n",
    "        dct_x = torch_apply(dct.dct, dct_x)\n",
    "\n",
    "        dct_x = dct_x.to(device)\n",
    "        y = y.to(device)            \n",
    "        \n",
    "        outputs_grad = []\n",
    "        outputs = []\n",
    "        \n",
    "        for i in range(len(models)):\n",
    "            out = models[i](dct_x[i, ...])\n",
    "            outputs_grad.append(out)\n",
    "            outputs.append(out.detach())\n",
    "        \n",
    "        #for i in range(len(models)):\n",
    "        #    train_slice(i, models[i], dct_x[i, ...], y, outputs, ops[i])\n",
    "            \n",
    "        Parallel(n_jobs=16, prefer=\"threads\", verbose=0)(\n",
    "            delayed(train_slice)(i, models[i], dct_x[i, ...], y, outputs, ops[i]) \\\n",
    "            for i in range(len(models))\n",
    "        )\n",
    "\n",
    "        res = torch.empty(shape[0], 10, shape[2])\n",
    "        for i in range(len(models)):\n",
    "            res[i, ...] = models[i](dct_x[i, ...])\n",
    "            \n",
    "        res = torch_apply(dct.idct, res).to(device)\n",
    "        res = scalar_tubal_func(res)\n",
    "        res = torch.transpose(res, 0, 1)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss = criterion(res, y)\n",
    "        \n",
    "        _, predicted = torch.max(res, 1)\n",
    "        total += y.size(0)\n",
    "        correct += predicted.eq(y).sum().item()\n",
    "        losses += total_loss\n",
    "        \n",
    "        pbar.update(batch_idx)\n",
    "        # print(total_loss)\n",
    "        # print(predicted.eq(y).sum().item() / y.size(0))\n",
    "        \n",
    "    loss_list.append(losses / total)\n",
    "    3acc_list.append(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    '''\n",
    "        tmp = torch_mp.get_context('spawn')\n",
    "        for model in models:\n",
    "            model.share_memory()\n",
    "        processes = []\n",
    "\n",
    "        for i in range(len(models)):\n",
    "            p = tmp.Process(target=train_slice, \n",
    "                args=(i, models[i], dct_x[i, ...], y, outputs, ops[i]))\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "        for p in processes: \n",
    "            p.join()\n",
    "        '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
